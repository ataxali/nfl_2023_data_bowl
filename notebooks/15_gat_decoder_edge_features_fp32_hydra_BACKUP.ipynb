{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b54f7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:12.049726Z",
     "start_time": "2023-01-09T21:40:07.543929Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.gridspec as gridspec\n",
    "#from curlyBrace import curlyBrace\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import os\n",
    "from sklearn import decomposition, preprocessing, manifold\n",
    "#import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import pickle\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing, decomposition, linear_model, metrics , feature_selection, model_selection, cross_decomposition, ensemble, tree, manifold, svm, neural_network \n",
    "import warnings\n",
    "import io\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import math\n",
    "from matplotlib import cm\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21303ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:12.061596Z",
     "start_time": "2023-01-09T21:40:12.051101Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "jtplot.reset()\n",
    "jtplot.reset()\n",
    "\n",
    "const = 12\n",
    "SMALL_SIZE = 8 + const  \n",
    "MEDIUM_SIZE = 10 + const\n",
    "BIGGER_SIZE = 12 + const\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "np.set_printoptions(edgeitems=20)\n",
    "np.core.arrayprint._line_width = 1000\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\"\"\"\n",
    "EMBEDDING_DIM = 512\n",
    "MAX_SENT_LEN = 50\n",
    "\n",
    "pe = PositionalEncoding(EMBEDDING_DIM, max_len = MAX_SENT_LEN)\n",
    "#src, tgt = enc_embedding(src), dec_embedding(tgt)\n",
    "# (SEQ_LEN, BATCH_SIZE, EMBEDDING_DIM)\n",
    "tgt = torch.zeros(20, 32, 512)\n",
    "tgt = pe(tgt)\n",
    "\n",
    "decoder_layer = nn.TransformerDecoderLayer(d_model=EMBEDDING_DIM, nhead=1, dim_feedforward=256, dropout=0)\n",
    "transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=1)\n",
    "memory = torch.rand(2, 32, 512)   # encoder out (SEQ_LEN, BATCH_SIZE, EMBEDDING_DIM)\n",
    "out = transformer_decoder(tgt, memory)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79bb73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:12.072673Z",
     "start_time": "2023-01-09T21:40:12.062995Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphAttentionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    https://github.com/Diego999/pyGAT/blob/master/layers.py\n",
    "    Simple GAT layer, similar to https://arxiv.org/abs/1710.10903\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
    "        super(GraphAttentionLayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.concat = concat\n",
    "\n",
    "        #self.W = nn.Parameter(torch.empty(size=(2*in_features, out_features)))\n",
    "        #nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        \n",
    "        self.W = nn.Linear(2*in_features,  #in_features, \n",
    "                           out_features)\n",
    "        nn.init.xavier_uniform_(self.W.weight, gain=1.414)\n",
    "        \n",
    "        #self.W_value = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
    "        #nn.init.xavier_uniform_(self.W_value.data, gain=1.414)\n",
    "        \n",
    "        self.W_value = nn.Linear(in_features, out_features)\n",
    "        nn.init.xavier_uniform_(self.W_value.weight, gain=1.414)\n",
    "        \n",
    "        #self.a = nn.Parameter(torch.empty(size=(out_features+4, 1)))\n",
    "        #nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "        \n",
    "        self.a = nn.Linear(out_features+4,\n",
    "                           1)\n",
    "        nn.init.xavier_uniform_(self.a.weight, gain=1.414)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "    #def forward(self, h, adj):\n",
    "    # adj = batch * n_times, n_nodes, n_nodes, n_features\n",
    "    def forward(self, h, adj):\n",
    "        \"\"\"\n",
    "\n",
    "        :param h: (batch_zize, number_nodes, in_features)\n",
    "        :param adj: (batch_size, number_nodes, number_nodes)\n",
    "        :return: (batch_zize, number_nodes, out_features)\n",
    "        \"\"\"\n",
    "        # batchwise matrix multiplication\n",
    "        # (batch_zize, number_nodes, in_features) * (in_features, out_features)\n",
    "        # -> (batch_zize, number_nodes, out_features)\n",
    "        Wh = h  #torch.matmul(h, self.W)\n",
    "        Wv = self.leakyrelu(self.W_value(h))  #torch.matmul(h, self.W_value)\n",
    "        Wv = F.dropout(Wv, self.dropout, training=self.training)\n",
    "\n",
    "        # (batch_zize, number_nodes, number_nodes, 2 * out_features)\n",
    "        a_input = self.batch_prepare_attentional_mechanism_input(Wh)  # used to be Wh\n",
    "        a_input = self.leakyrelu(self.W(a_input))  #self.leakyrelu(torch.matmul(a_input, self.W))\n",
    "        a_input = torch.cat([a_input, adj], dim=-1)\n",
    "        a_input = F.dropout(a_input, self.dropout, training=self.training)\n",
    "\n",
    "        # (batch_zize, number_nodes, number_nodes, 2 * out_features) * (2 * out_features, 1)\n",
    "        # -> (batch_zize, number_nodes, number_nodes, 1)\n",
    "        e = self.a(a_input)  #torch.matmul(a_input, self.a)\n",
    "\n",
    "        # (batch_zize, number_nodes, number_nodes)\n",
    "        e = self.leakyrelu(e.squeeze(-1))\n",
    "\n",
    "        # (batch_zize, number_nodes, number_nodes)\n",
    "        #zero_vec = -9e15 * torch.ones_like(e)\n",
    "\n",
    "        # (batch_zize, number_nodes, number_nodes)\n",
    "        #attention = torch.where(adj > 0, e, zero_vec)\n",
    "        attention = e\n",
    "\n",
    "        # (batch_zize, number_nodes, number_nodes)\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "\n",
    "        # (batch_zize, number_nodes, number_nodes)\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "\n",
    "        # batched matrix multiplication (batch_zize, number_nodes, out_features)\n",
    "        h_prime = torch.matmul(attention, Wv)  # same as bmm\n",
    "    \n",
    "        if self.concat:\n",
    "            return h_prime + Wv, attention, Wv  #F.elu(h_prime) + Wv\n",
    "        else:\n",
    "            return h_prime + Wv, attention, Wv\n",
    "\n",
    "    def batch_prepare_attentional_mechanism_input(self, Wh):\n",
    "        \"\"\"\n",
    "        with batch training\n",
    "        :param Wh: (batch_zize, number_nodes, out_features)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        B, M, E = Wh.shape # (batch_zize, number_nodes, out_features)\n",
    "        Wh_repeated_in_chunks = Wh.repeat_interleave(M, dim=1)  # (B, M*M, E)\n",
    "        Wh_repeated_alternating = Wh.repeat(1, M, 1)  # (B, M*M, E)\n",
    "        all_combinations_matrix = torch.cat([Wh_repeated_in_chunks, Wh_repeated_alternating], dim=-1)  # (B, M*M,2E)\n",
    "        return all_combinations_matrix.view(B, M, M, 2 * E)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e14e53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:12.080972Z",
     "start_time": "2023-01-09T21:40:12.073889Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer_Decoder(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads):\n",
    "        super(Transformer_Decoder, self).__init__()\n",
    "        self.embedding_dim = nhid * nheads\n",
    "        self.dropout = dropout\n",
    "        self.pe = PositionalEncoding(d_model=self.embedding_dim, dropout=0, max_len=25)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=self.embedding_dim, nhead=1, dim_feedforward=self.embedding_dim, dropout=0)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=1)\n",
    "        self.in_embed = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        self.out_embed = nn.Linear(self.embedding_dim, nclass)\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "        nn.init.xavier_uniform_(self.in_embed.weight, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.out_embed.weight, gain=1.414)\n",
    "        \n",
    "    def forward(self, node_embeddings, exp_in, gat_embeddings_tf_in, gat_embeddings, n_frame_pred):\n",
    "        decoder_memory = gat_embeddings.sum(1).unsqueeze(1).permute((1, 0, 2))\n",
    "        decoder_memory = decoder_memory.repeat(1, n_frame_pred*22, 1)\n",
    "        decoder_memory = F.dropout(decoder_memory, self.dropout, training=self.training)\n",
    "        node_input_t = self.leakyrelu(self.in_embed(gat_embeddings_tf_in)).permute((1, 0, 2))\n",
    "        node_input_t = self.pe(node_input_t)\n",
    "        decoder_target = node_input_t  #self.pe(node_input_t.permute((1, 0, 2)))\n",
    "        decoder_target = F.dropout(decoder_target, self.dropout, training=self.training)\n",
    "        decoder_out = self.transformer_decoder(decoder_target, decoder_memory)\n",
    "        decoder_out = F.dropout(decoder_out, self.dropout, training=self.training)\n",
    "        predictor_out = self.out_embed(decoder_out).permute((1, 0, 2))\n",
    "        predictor_out = predictor_out[:, -1, :]\n",
    "        predictor_out = unflatted_batch_dim(predictor_out)\n",
    "        return predictor_out + exp_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b32977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:12.086617Z",
     "start_time": "2023-01-09T21:40:12.082006Z"
    }
   },
   "outputs": [],
   "source": [
    "class GAT_Encoder(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads):\n",
    "        \"\"\"Dense version of GAT.\"\"\"\n",
    "        super(GAT_Encoder, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.attentions = [GraphAttentionLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) for _ in range(nheads)]\n",
    "        for i, attention in enumerate(self.attentions):\n",
    "            self.add_module('attention_{}'.format(i), attention)\n",
    "        \n",
    "    def forward(self, x, exp_in, adj):\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        #x = torch.cat([att(x, adj) for att in self.attentions], dim=-1)\n",
    "        x, attention, node_embeddings = self.attentions[0](x, adj)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        return x, attention, node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f9034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:12.091976Z",
     "start_time": "2023-01-09T21:40:12.087699Z"
    }
   },
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads):\n",
    "        \"\"\"Dense version of GAT.\"\"\"\n",
    "        super(GAT, self).__init__()\n",
    "        self.dropout = dropout\n",
    "            \n",
    "        self.gat_encoder = GAT_Encoder(nfeat, nhid, nclass, dropout, alpha, nheads)\n",
    "        self.tformer_decoder = Transformer_Decoder(nfeat, nhid, nclass, dropout, alpha, nheads)\n",
    "        self.norm = nn.LayerNorm(nhid)\n",
    "        \n",
    "    def forward(self, x, exp_in, adj, n_frame_pred):\n",
    "        node_embeddings = x\n",
    "        gat_embeddings, gat_attn_matrix, gat_node_embeddings = self.gat_encoder(x, exp_in, adj)\n",
    "        gat_embeddings = self.norm(gat_embeddings)\n",
    "        gat_embeddings_tf_in = flatten_batch_dim(gat_embeddings).unsqueeze(1).repeat(1, n_frame_pred, 1)\n",
    "        tformer_predictions = self.tformer_decoder(node_embeddings, exp_in, gat_embeddings_tf_in, gat_embeddings, n_frame_pred)\n",
    "        return tformer_predictions, gat_embeddings, gat_attn_matrix, gat_node_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96106232",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d1b78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-08T18:36:46.237866Z",
     "start_time": "2023-01-08T18:36:44.880854Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plays_df = pd.read_csv('./plays.csv')\n",
    "games_df = pd.read_csv('./games.csv')\n",
    "players_df = pd.read_csv('./players.csv')\n",
    "pff_df = pd.read_csv('./pffScoutingData.csv')\n",
    "snap_data = pickle.load(open('./ts_player_features_game_playid.pickle', 'rb'))\n",
    "# ts_features, delta_features, r_features, player_features, game, play_id\n",
    "player_embed, dense_player_embed = pickle.load(open('./player_embed_dense.pickle', 'rb'))\n",
    "\n",
    "\n",
    "nflid_to_idx = dict()\n",
    "for i, nflid in enumerate(players_df.nflId.values.flatten()):\n",
    "    assert nflid not in nflid_to_idx\n",
    "    nflid_to_idx[nflid] = i\n",
    "\n",
    "assert i == 1678\n",
    "nflid_to_idx[0] = 1679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7dd03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-08T18:36:46.259379Z",
     "start_time": "2023-01-08T18:36:46.239443Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625db11a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-07T10:38:33.023235Z",
     "start_time": "2023-01-07T10:38:30.141457Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "edge_features = [np.concatenate((snap_data[i][1], snap_data[i][2]), axis=3) for i in range(len(snap_data))]\n",
    "edge_features = np.array(edge_features)\n",
    "edge_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b7d1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-07T10:38:35.889996Z",
     "start_time": "2023-01-07T10:38:35.759701Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ts_features = np.array([snap_data[i][0] for i in range(len(snap_data))])\n",
    "ts_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f621960e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-07T10:39:17.265194Z",
     "start_time": "2023-01-07T10:39:01.685785Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "player_roles = np.zeros((len(snap_data), 22))\n",
    "for i in tqdm(range(len(snap_data))):\n",
    "    _, _, _, player_features_i, game, play_id = snap_data[i]\n",
    "    player_roles[i, :] = pff_df[(pff_df.gameId == game) & (pff_df.playId == play_id)].set_index('nflId').reindex(player_features_i).pff_role.isin(['Pass Rush', 'Pass Block']).values.astype(int)\n",
    "player_roles = np.repeat(player_roles[:, np.newaxis, :], edge_features.shape[1], 1)\n",
    "player_roles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7cb710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-07T10:39:25.016552Z",
     "start_time": "2023-01-07T10:39:19.168974Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#player_embed = dense_player_embed\n",
    "player_embed = np.concatenate((player_embed, np.zeros((1, player_embed.shape[1]))), axis=0)\n",
    "\n",
    "#player_features = np.stack([snap_data[idx][1] for idx in train_idxs], axis=2)\n",
    "player_features = []\n",
    "for idx in tqdm(range(len(snap_data)), ncols=1000):\n",
    "    player_features_i = snap_data[idx][3]\n",
    "    player_features.append(player_embed[[nflid_to_idx[player_id] for player_id in player_features_i], :])\n",
    "player_features = np.stack(player_features, axis=2).swapaxes(0, 2).swapaxes(1, 2)\n",
    "#player_features = np.concatenate((player_features,\n",
    "#                                  np.stack([snap_data[idx][1] for idx in range(len(snap_data))], axis=0)[:, :, 1:]),\n",
    "#                                 axis=2)\n",
    "#player_features = np.stack([snap_data[idx][1] for idx in range(len(snap_data))], axis=0)\n",
    "#player_features = player_features[:, :, 1:]\n",
    "\n",
    "game_ids = np.stack([snap_data[idx][4] for idx in range(len(snap_data))], axis=0)\n",
    "play_ids = np.stack([snap_data[idx][5] for idx in range(len(snap_data))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b76241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T10:21:31.042008Z",
     "start_time": "2023-01-06T10:21:15.661751Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_game_ids = np.stack([snap_data[idx][4] for idx in range(len(snap_data))], axis=0)\n",
    "train_idxs = []\n",
    "test_idxs = []\n",
    "valid_idxs = []\n",
    "for i, game_id in enumerate(tqdm(all_game_ids, ncols=1000)):\n",
    "    if games_df[games_df.gameId == game_id].week.values.flatten()[0] < 7:\n",
    "        train_idxs.append(i)\n",
    "    elif games_df[games_df.gameId == game_id].week.values.flatten()[0] == 7:\n",
    "        valid_idxs.append(i)\n",
    "    else:\n",
    "        test_idxs.append(i)\n",
    "        \n",
    "        \n",
    "#[['pff_hit', 'pff_hurry', 'pff_sack']]\n",
    "\n",
    "y = []\n",
    "for i in tqdm(range(len(snap_data)), ncols=1000):\n",
    "    _, _, _, _, game, play_id = snap_data[i]\n",
    "    #y_i = int(np.any(pff_df[(pff_df.gameId == game) & (pff_df.playId == play_id)][['pff_hit', 'pff_hurry', 'pff_sack']].values == 1))\n",
    "    #y_i = np.any(pff_df[(pff_df.gameId == game) & (pff_df.playId == play_id)][['pff_hit', 'pff_hurry', 'pff_sack']].fillna(0).values, axis=0).astype(int).sum()\n",
    "    y_sack = int(np.any(pff_df[(pff_df.gameId == game) & (pff_df.playId == play_id)][['pff_sack']].fillna(0).values.flatten()))\n",
    "    y_hurry = int(np.any(pff_df[(pff_df.gameId == game) & (pff_df.playId == play_id)][['pff_hurry']].fillna(0).values.flatten()))\n",
    "    y.append(y_i)\n",
    "play_outcomes = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b9ee11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T10:21:49.815916Z",
     "start_time": "2023-01-06T10:21:31.043579Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pickle.dump((player_features, edge_features, ts_features, player_roles, train_idxs, valid_idxs, test_idxs), open('./ssl_next_frame_ts.pickle', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf446bdb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134a32c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:14.614163Z",
     "start_time": "2023-01-09T21:40:12.093011Z"
    }
   },
   "outputs": [],
   "source": [
    "player_features, edge_features, ts_features, player_roles, train_idxs, valid_idxs, test_idxs = pickle.load(open('./ssl_next_frame_ts_gpt.pickle', 'rb'))\n",
    "#player_features = player_features[:100]\n",
    "#edge_features = edge_features[:100]\n",
    "#ts_features = ts_features[:100]\n",
    "#play_roles = player_roles[:100]\n",
    "#train_idxs = train_idxs[:100]\n",
    "#valid_idxs = []\n",
    "#test_idxs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b4d04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:26.779997Z",
     "start_time": "2023-01-09T21:40:14.616508Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyper params, input\n",
    "FP = np.float32\n",
    "\n",
    "torch_device = torch.device('cuda:0') \n",
    "edge_features_gpu = torch.from_numpy(np.nan_to_num(edge_features.astype(FP), nan=0, posinf=0, neginf=0)).to(torch_device)\n",
    "\n",
    "edges = edge_features_gpu\n",
    "#node_features = player_features_gpu.unsqueeze(1).repeat(1, edge_features_gpu.size(1), 1, 1)\n",
    "player_features_cpu = torch.from_numpy(player_features.astype(FP))\n",
    "ts_features_cpu = torch.from_numpy(ts_features.astype(FP))\n",
    "node_features = torch.cat([player_features_cpu.unsqueeze(1).repeat(1, edge_features_gpu.size(1), 1, 1), \n",
    "                           ts_features_cpu], dim=-1).to(torch_device)\n",
    "\n",
    "player_roles_batch = player_roles[:, :, :]\n",
    "player_roles_batch = np.repeat(player_roles_batch[:, :, :, np.newaxis], 2, 3)\n",
    "player_roles_batch_cpu = player_roles_batch.copy()\n",
    "\n",
    "print(node_features.size())\n",
    "print(edges.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d395e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:26.787434Z",
     "start_time": "2023-01-09T21:40:26.781651Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_features_gpu = node_features[:, :, :, [-9, -8]]\n",
    "#ts_features_gpu = node_features[:, :, :, -4:-2]\n",
    "ts_features_gpu.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ce958d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:26.793599Z",
     "start_time": "2023-01-09T21:40:26.788488Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_features_gpu[0, :, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67cf85f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:26.798124Z",
     "start_time": "2023-01-09T21:40:26.794603Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_features_gpu[0, :, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174981a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:26.802070Z",
     "start_time": "2023-01-09T21:40:26.799104Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_idxs = [x for x in train_idxs if x not in [334, 1571, 949]]\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i+n]\n",
    "        \n",
    "def flatten_batch_dim(x):\n",
    "    return x.reshape((-1,) + x.shape[2:])\n",
    "\n",
    "def unflatted_batch_dim(x):\n",
    "    return x.reshape((-1, 22, x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2f389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:40:26.903054Z",
     "start_time": "2023-01-09T21:40:26.803078Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "gat = GAT(nfeat=node_features.size(3), \n",
    "          nhid=embedding_dim, \n",
    "          nclass=2, \n",
    "          dropout=0.1, alpha=0.01, nheads=1)\n",
    "gat.load_state_dict(torch.load('gat_SSL_trained.pt'))\n",
    "gat = gat.to(torch_device)\n",
    "\n",
    "leakyrelu = nn.LeakyReLU()\n",
    "LR = 1e-4\n",
    "optimizer = torch.optim.Adam(gat.parameters(), lr=LR, weight_decay=1e-2)\n",
    "#pe = PositionalEncoding(d_model=embedding_dim, dropout=0, max_len=25)\n",
    "\n",
    "mse = nn.MSELoss()  #nn.L1Loss()\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621eb12e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:45:23.065121Z",
     "start_time": "2023-01-09T21:40:26.904385Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_plot(epoch_i):\n",
    "    #if epoch_i % print_freq == 0:\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(train_loss_history[1:][-print_history:])\n",
    "    plt.plot(test_loss_history[1:][-print_history:])\n",
    "    plt.plot(val_loss_history[1:][-print_history:])\n",
    "    plt.title(f'{epoch_i + 1} / {n_total_epochs}')\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    #plt.ylim((0, 0.03))\n",
    "    plt.show()\n",
    "    print('train loss')\n",
    "    print(np.round(train_loss_history, 4))\n",
    "    print('valid loss')\n",
    "    print(np.round(val_loss_history, 4))\n",
    "    print('test  loss')\n",
    "    print(np.round(test_loss_history, 4))\n",
    "\n",
    "\n",
    "n_total_epochs = 5000\n",
    "print_freq = 1\n",
    "print_history = 200\n",
    "ts_idx_to_input = np.array([0, 4, 9])  #np.arange(0, 10)\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "for epoch_i in tqdm(range(n_total_epochs), ncols=1000):\n",
    "    batch_losses = []\n",
    "    for train_batch in chunks(np.random.choice(train_idxs, size=len(train_idxs), replace=False),\n",
    "                              batch_size):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        gat.zero_grad()\n",
    "        \n",
    "        n_frame_pred = np.random.choice(np.arange(1, 16))   #  [1, 5, 10])\n",
    "        ts_idx_to_input = np.random.choice(np.arange(20-n_frame_pred), size=8)\n",
    "        #if n_frame_pred < 5:\n",
    "        #    ts_idx_to_input = np.random.choice(np.arange(15), size=3)\n",
    "        #elif n_frame_pred < 10:\n",
    "        #    ts_idx_to_input = np.random.choice(np.arange(10), size=3)\n",
    "        #else:\n",
    "        #    ts_idx_to_input = np.random.choice(np.arange(5), size=3)\n",
    "        #n_frame_pred = 5\n",
    "        #ts_idx_to_input = np.array([0, 5, 10])\n",
    "        \n",
    "        dat_in = flatten_batch_dim(node_features[train_batch, :, :, :][:, ts_idx_to_input, :, :])\n",
    "        exp_out = flatten_batch_dim(ts_features_gpu[train_batch, :, :, :][:, ts_idx_to_input+n_frame_pred, :, :])\n",
    "        exp_in = flatten_batch_dim(ts_features_gpu[train_batch, :, :, :][:, ts_idx_to_input, :, :])\n",
    "        edges_in = flatten_batch_dim(edges[train_batch, :, :, :, :][:, ts_idx_to_input, :, :, :])\n",
    "\n",
    "        predictor_out, _, _, _ = gat(dat_in, exp_in, edges_in, n_frame_pred)\n",
    "\n",
    "        player_roles_batch = torch.from_numpy(player_roles_batch_cpu[train_batch, :, :, :][:, ts_idx_to_input, :, :].astype(np.float32)).to(torch_device)\n",
    "        #player_roles_batch = player_roles_gpu[train_batch, :, :, :]\n",
    "        player_roles_batch = (flatten_batch_dim(player_roles_batch) * 0.2) + 1\n",
    "        loss = mse(predictor_out*player_roles_batch, exp_out*player_roles_batch)\n",
    "        #loss = mse(predictor_out, exp_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "    train_loss_history.append(np.mean(batch_losses))\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_frame_pred = 5\n",
    "        ts_idx_to_input = np.array([0, 5, 10])\n",
    "        \n",
    "        test_loss = []\n",
    "        for train_batch in chunks(np.random.choice(test_idxs, size=len(test_idxs), replace=False),\n",
    "                                  batch_size):\n",
    "            dat_in = flatten_batch_dim(node_features[train_batch, :, :, :][:, ts_idx_to_input, :, :])\n",
    "            exp_out = flatten_batch_dim(ts_features_gpu[train_batch, :, :, :][:, ts_idx_to_input+n_frame_pred, :, :])\n",
    "            exp_in = flatten_batch_dim(ts_features_gpu[train_batch, :, :, :][:, ts_idx_to_input, :, :])\n",
    "            edges_in = flatten_batch_dim(edges[train_batch, :, :, :, :][:, ts_idx_to_input, :, :, :])\n",
    "            predictor_out, _, _, _ = gat(dat_in, exp_in, edges_in, n_frame_pred)\n",
    "            player_roles_batch = torch.from_numpy(player_roles_batch_cpu[train_batch, :, :, :][:, ts_idx_to_input, :, :].astype(np.float32)).to(torch_device)\n",
    "            #player_roles_batch = player_roles_gpu[train_batch, :, :, :]\n",
    "            player_roles_batch = (flatten_batch_dim(player_roles_batch) * 0.2) + 1\n",
    "            loss = mse(predictor_out*player_roles_batch, exp_out*player_roles_batch)\n",
    "            #loss = mse(predictor_out, exp_out)\n",
    "            test_loss.append(loss.item())\n",
    "\n",
    "        val_loss = []\n",
    "        for train_batch in chunks(np.random.choice(valid_idxs, size=len(valid_idxs), replace=False),\n",
    "                                  batch_size):\n",
    "            dat_in = flatten_batch_dim(node_features[train_batch, :, :, :][:, ts_idx_to_input, :, :])\n",
    "            exp_out = flatten_batch_dim(ts_features_gpu[train_batch, :, :, :][:, ts_idx_to_input+n_frame_pred, :, :])\n",
    "            exp_in = flatten_batch_dim(ts_features_gpu[train_batch, :, :, :][:, ts_idx_to_input, :, :])\n",
    "            edges_in = flatten_batch_dim(edges[train_batch, :, :, :, :][:, ts_idx_to_input, :, :, :])\n",
    "            predictor_out, _, _, _ = gat(dat_in, exp_in, edges_in, n_frame_pred)\n",
    "            player_roles_batch = torch.from_numpy(player_roles_batch_cpu[train_batch, :, :, :][:, ts_idx_to_input, :, :].astype(np.float32)).to(torch_device)\n",
    "            #player_roles_batch = player_roles_gpu[train_batch, :, :, :]\n",
    "            player_roles_batch = (flatten_batch_dim(player_roles_batch) * 0.2) + 1\n",
    "            loss = mse(predictor_out*player_roles_batch, exp_out*player_roles_batch)\n",
    "            #loss = mse(predictor_out, exp_out)\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "        test_loss_history.append(np.mean(test_loss))\n",
    "        val_loss_history.append(np.mean(val_loss))\n",
    "\n",
    "    #if len(val_loss_history) > print_history:\n",
    "    #    if np.min(val_loss_history) < (0.95*val_loss_history[-1]):\n",
    "    #        display_plot(epoch_i)\n",
    "    #        print('stopping per validation')\n",
    "    #        break\n",
    "\n",
    "    display_plot(epoch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52905f1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:45:23.066528Z",
     "start_time": "2023-01-09T21:40:14.075Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(gat.cpu().state_dict(), './gat_SSL_trained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143774ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-08T21:19:11.222992Z",
     "start_time": "2023-01-08T19:59:01.334Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss_history[1:])\n",
    "plt.plot(test_loss_history[1:])\n",
    "plt.plot(val_loss_history[1:])\n",
    "plt.title(f'{epoch_i + 1} / {n_total_epochs}')\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_ylim(bottom=0)\n",
    "#plt.ylim((0, 0.03))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77642e8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-08T09:14:11.197157Z",
     "start_time": "2023-01-08T09:14:11.193595Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loss_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6884c73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb5714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c593adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T04:28:53.005787Z",
     "start_time": "2023-01-06T04:26:08.264Z"
    }
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "## end of training ##\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d432cd22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-08T09:54:13.080400Z",
     "start_time": "2023-01-08T09:54:13.077248Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abd1e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-08T21:19:28.331582Z",
     "start_time": "2023-01-08T21:19:27.691294Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_batch = np.random.choice(train_idxs, 1)\n",
    "n_frame_pred = 5\n",
    "ts_idx_to_input = np.array([0, 5, 10, 15])\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_loss = []\n",
    "    \n",
    "    dat_in = flatten_batch_dim(node_features[train_batch, :, :, :][:, ts_idx_to_input, :, :])\n",
    "    exp_in = flatten_batch_dim(ts_features_gpu[train_batch, :, :, :][:, ts_idx_to_input, :, :])\n",
    "    edges_in = flatten_batch_dim(edges[train_batch, :, :, :, :][:, ts_idx_to_input, :, :, :])\n",
    "\n",
    "    predictor_out, _, _, _ = gat(dat_in, exp_in, edges_in, n_frame_pred)\n",
    "    \n",
    "plt.figure(figsize=(15, 9))\n",
    "plot_dat = ts_features_gpu[train_batch[0], :, :, :2]\n",
    "for i in range(plot_dat.size(1)):\n",
    "    #for j in range(20):\n",
    "    #    plt.scatter(ts_features_gpu[train_batch[0], j, i, 0].detach().cpu().numpy(),\n",
    "    #                ts_features_gpu[train_batch[0], j, i, 1].detach().cpu().numpy(), \n",
    "    #                c='C0' if i < 11 else 'C1', alpha=1-(j/20))\n",
    "    \n",
    "    plt.plot(ts_features_gpu[train_batch[0], :, i, 0].detach().cpu().numpy(),\n",
    "             ts_features_gpu[train_batch[0], :, i, 1].detach().cpu().numpy(), \n",
    "             color='C0' if i < 11 else 'C1', alpha=1, linestyle='--')\n",
    "    plt.scatter(ts_features_gpu[train_batch[0], 0, i, 0].detach().cpu().numpy(),\n",
    "             ts_features_gpu[train_batch[0], 0, i, 1].detach().cpu().numpy(), \n",
    "             c='C0' if i < 11 else 'C1', alpha=1, marker='o')\n",
    "    plt.scatter(ts_features_gpu[train_batch[0], -1, i, 0].detach().cpu().numpy(),\n",
    "             ts_features_gpu[train_batch[0], -1, i, 1].detach().cpu().numpy(), \n",
    "             c='C0' if i < 11 else 'C1', alpha=1, marker='x')\n",
    "\n",
    "    for t in range(predictor_out.size(0)):\n",
    "        plt.plot([exp_in[t, i, 0].detach().cpu().numpy().flatten()[0], \n",
    "                  predictor_out[t, i, 0].detach().cpu().numpy().flatten()[0]],\n",
    "                 [exp_in[t, i, 1].detach().cpu().numpy().flatten()[0], \n",
    "                  predictor_out[t, i, 1].detach().cpu().numpy().flatten()[0]], \n",
    "                 c='C0' if i < 11 else 'C1', alpha=1)\n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920c3ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-08T09:12:59.163139Z",
     "start_time": "2023-01-08T09:12:58.834729Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    dat_in = flatten_batch_dim(node_features[train_batch, 0:1, :, :])\n",
    "\n",
    "    init_exp_in = ts_features_gpu[train_batch, 0:1, :, :]\n",
    "    init_edges_in = edges[train_batch, 0:1, :, :, :]\n",
    "    later_edges_in = torch.zeros((1, 1, 22, 22, 4)).to(torch_device)\n",
    "    predictor_out = None\n",
    "    all_preds_out = []\n",
    "    n_frames_predict = 3\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in tqdm(range(n_frames_predict)):\n",
    "            #\"\"\"\n",
    "            if i == 0:\n",
    "                exp_in = init_exp_in\n",
    "                edges_in = init_edges_in\n",
    "            else:\n",
    "                exp_in = predictor_out.unsqueeze(0)\n",
    "                for x_i in range(22):\n",
    "                    for x_j in range(22):\n",
    "                        idx_counter = 0\n",
    "                        for x_k in range(predictor_out.size(2)):\n",
    "                            later_edges_in[0, 0, x_i, x_j, idx_counter] = (exp_in[0, 0, x_i, x_k] - exp_in[0, 0, x_j, x_k])**2\n",
    "                            idx_counter += 1\n",
    "                        for x_k in range(predictor_out.size(2)):\n",
    "                            later_edges_in[0, 0, x_i, x_j, idx_counter] = exp_in[0, 0, x_i, x_k] * exp_in[0, 0, x_j, x_k]\n",
    "                            idx_counter += 1\n",
    "\n",
    "                        #later_edges_in[0, x_i, x_j, 0] = (predictor_out[0, x_i, 0] - predictor_out[0, x_j, 0])**2\n",
    "                        #later_edges_in[0, x_i, x_j, 1] = (predictor_out[0, x_i, 1] - predictor_out[0, x_j, 1])**2\n",
    "                        #later_edges_in[0, x_i, x_j, 2] = (predictor_out[0, x_i, 0] * predictor_out[0, x_j, 0])\n",
    "                        #later_edges_in[0, x_i, x_j, 3] = (predictor_out[0, x_i, 1] * predictor_out[0, x_j, 1])\n",
    "                        edges_in = later_edges_in\n",
    "            #\"\"\"\n",
    "            #exp_in = ts_features_gpu[train_batch, (i):(i+1), :, :2]\n",
    "            #edges_in = edges[train_batch, (i):(i+1), :, :, :]\n",
    "\n",
    "            exp_in = flatten_batch_dim(exp_in)\n",
    "            edges_in = flatten_batch_dim(edges_in)\n",
    "            predictor_out = gat(dat_in, exp_in, edges_in, n_frame_pred)\n",
    "            all_preds_out.append(predictor_out.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe19c2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-07T23:31:25.205465Z",
     "start_time": "2023-01-07T23:31:24.433983Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plot_dat = ts_features_gpu[train_batch[0], :, :, :2]\n",
    "for i in range(len(all_preds_out)):\n",
    "    for j in range(22):\n",
    "        plt.scatter(all_preds_out[i][0, j, 0].detach().cpu().numpy(),\n",
    "                    all_preds_out[i][0, j, 1].detach().cpu().numpy(), \n",
    "                    c='C0' if j < 11 else 'C1', alpha=1-(i/n_frames_predict))\n",
    "\n",
    "for j in range(22):\n",
    "    n_points = 15\n",
    "    plt.plot(plot_dat[:n_points, j, 0].detach().cpu().numpy(),\n",
    "             plot_dat[:n_points, j, 1].detach().cpu().numpy(), \n",
    "             color='C0' if j < 11 else 'C1', linewidth=3)\n",
    "    plt.scatter(plot_dat[0, j, 0].detach().cpu().numpy(),\n",
    "             plot_dat[0, j, 1].detach().cpu().numpy(), \n",
    "             c='C0' if j < 11 else 'C1', marker='x')\n",
    "    plt.scatter(plot_dat[n_points-1, j, 0].detach().cpu().numpy(),\n",
    "             plot_dat[n_points-1, j, 1].detach().cpu().numpy(), \n",
    "             c='C0' if j < 11 else 'C1', marker='^')\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8d45a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-07T23:31:40.441632Z",
     "start_time": "2023-01-07T23:31:40.309447Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    dat_in = flatten_batch_dim(node_features[train_batch, 0:1, :, :])\n",
    "\n",
    "    init_exp_in = ts_features_gpu[train_batch, 0:1, :, :]\n",
    "    init_edges_in = edges[train_batch, 0:1, :, :, :]\n",
    "    later_edges_in = torch.zeros((1, 1, 22, 22, 4)).to(torch_device)\n",
    "    predictor_out = None\n",
    "    all_preds_out = []\n",
    "    n_frames_predict = 3\n",
    "    players_to_sim = [0]\n",
    "    players_not_to_sim = [x for x in range(22) if x not in players_to_sim]\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in tqdm(range(n_frames_predict)):\n",
    "            #\"\"\"\n",
    "            if i == 0:\n",
    "                exp_in = init_exp_in  #flatten_batch_dim(init_exp_in)\n",
    "                edges_in = init_edges_in #flatten_batch_dim(init_edges_in)\n",
    "            else:\n",
    "                exp_in_copy = ts_features_gpu[train_batch, (i*n_frame_pred):((i*n_frame_pred)+1), :, :].clone()\n",
    "                for p_i, p in enumerate(players_to_sim):\n",
    "                    exp_in_copy[0, 0, p, :] = predictor_out[0, p, :]\n",
    "                exp_in = exp_in_copy  #predictor_out.unsqueeze(0)\n",
    "                for x_i in range(22):\n",
    "                    for x_j in range(22):\n",
    "                        idx_counter = 0\n",
    "                        for x_k in range(predictor_out.size(2)):\n",
    "                            later_edges_in[0, 0, x_i, x_j, idx_counter] = (exp_in[0, x_i, x_k] - exp_in[0, 0, x_j, x_k])**2\n",
    "                            idx_counter += 1\n",
    "                        for x_k in range(predictor_out.size(2)):\n",
    "                            later_edges_in[0, 0, x_i, x_j, idx_counter] = exp_in[0, x_i, x_k] * exp_in[0, 0, x_j, x_k]\n",
    "                            idx_counter += 1\n",
    "\n",
    "                        #later_edges_in[0, x_i, x_j, 0] = (predictor_out[0, x_i, 0] - predictor_out[0, x_j, 0])**2\n",
    "                        #later_edges_in[0, x_i, x_j, 1] = (predictor_out[0, x_i, 1] - predictor_out[0, x_j, 1])**2\n",
    "                        #later_edges_in[0, x_i, x_j, 2] = (predictor_out[0, x_i, 0] * predictor_out[0, x_j, 0])\n",
    "                        #later_edges_in[0, x_i, x_j, 3] = (predictor_out[0, x_i, 1] * predictor_out[0, x_j, 1])\n",
    "                        edges_in = later_edges_in\n",
    "\n",
    "            #\"\"\"\n",
    "            #exp_in = ts_features_gpu[train_batch, (i):(i+1), :, :2]\n",
    "            #edges_in = edges[train_batch, (i):(i+1), :, :, :]\n",
    "\n",
    "            exp_in = flatten_batch_dim(exp_in)\n",
    "            edges_in = flatten_batch_dim(edges_in)\n",
    "            predictor_out = gat(dat_in, exp_in, edges_in, n_frame_pred)\n",
    "            all_preds_out.append(predictor_out.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427dbe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-07T12:23:40.180555Z",
     "start_time": "2023-01-07T12:23:39.765061Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plot_dat = ts_features_gpu[train_batch[0], :, :, :2]\n",
    "for i in range(len(all_preds_out)):\n",
    "    for j in range(22):\n",
    "        c = 'C0' if j < 11 else 'C1'\n",
    "        if j in players_to_sim: c = 'r'\n",
    "        plt.scatter(all_preds_out[i][0, j, 0].detach().cpu().numpy(),\n",
    "                    all_preds_out[i][0, j, 1].detach().cpu().numpy(), \n",
    "                    c=c, alpha=1-(i/n_frames_predict))\n",
    "\n",
    "for j in range(22):\n",
    "    n_points = 15\n",
    "    c = 'C0' if j < 11 else 'C1'\n",
    "    if j in players_to_sim: c = 'r'\n",
    "\n",
    "    plt.plot(plot_dat[:n_points, j, 0].detach().cpu().numpy(),\n",
    "             plot_dat[:n_points, j, 1].detach().cpu().numpy(), \n",
    "             color=c, linewidth=3)\n",
    "    plt.scatter(plot_dat[0, j, 0].detach().cpu().numpy(),\n",
    "             plot_dat[0, j, 1].detach().cpu().numpy(), \n",
    "             c=c, marker='x')\n",
    "    plt.scatter(plot_dat[n_points-1, j, 0].detach().cpu().numpy(),\n",
    "             plot_dat[n_points-1, j, 1].detach().cpu().numpy(), \n",
    "             c=c, marker='^')\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8f2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f99056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a3bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b849e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639d136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569836df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83241c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_2021",
   "language": "python",
   "name": "pytorch_2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
